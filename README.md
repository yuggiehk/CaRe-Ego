# CaRe-Ego
[CaRe-Ego: Contact-aware Relationship Modeling for Egocentric Interactive Hand-object Segmentation]()

Yuejiao Su, Yi Wang, and Lap-Pui Chau

## Qualitative Results
Comparison results on the EgoHOS in-domain test set.
![1](https://github.com/yuggiehk/CaRe-Ego/blob/main/imgs/1.png)

Comparison results on the EgoHOS out-of-domain test set.
![2](https://github.com/yuggiehk/CaRe-Ego/blob/main/imgs/2.png)

Comparison results on the out-of-distribution mini-HOI4D dataset. The dataset of mini-HOI4D will be released soon.
![3](https://github.com/yuggiehk/CaRe-Ego/blob/main/imgs/3.png)

## Quantitative Results
Comparison results on the EgoHOS in-domain test set measured by IoU/Acc and mIoU/mAcc. 
![1](https://github.com/user-attachments/assets/ff38b294-11af-4046-991c-91110f5b406a)

Comparison results on the EgoHOS out-of-domain test set measured by IoU/Acc and mIoU/mAcc. 
![图片_20240718105915](https://github.com/user-attachments/assets/e05bf7e3-5f61-49d4-b4ce-a2038e265d6b)

Comparison results on the mini-HOI4D test set measured by IoU/Acc and mIoU/mAcc. 
![图片_20240718105954](https://github.com/user-attachments/assets/d831c34b-568c-435e-9f1b-7264f13b35a2)

## Video Demonstrations
Although the CaRe-Ego is performed on Egocentric images, we can validate it on out-of-distribution videos frame-by-frame.

![dynamic_video_results](https://github.com/yuggiehk/CaRe-Ego/blob/main/imgs/video1.gif)

![2](https://github.com/yuggiehk/CaRe-Ego/blob/main/imgs/video2.gif)

![3](https://github.com/yuggiehk/CaRe-Ego/blob/main/imgs/video3.gif)

![4](https://github.com/yuggiehk/CaRe-Ego/blob/main/imgs/video4.gif)


## Acknowledgements
The research work was conducted in the JC STEM Lab of Machine Learning and Computer Vision funded by The Hong Kong Jockey Club Charities Trust.

The code of the CaRe-Ego is built upon the [MMsegmentation](https://github.com/open-mmlab/mmsegmentation) codebase, thanks for their work.








